{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","colab":{"collapsed_sections":[],"provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":89777,"databundleVersionId":10379392,"sourceType":"competition"}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport pandas as pd\nfrom PIL import Image\nfrom tqdm import tqdm\n\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn as nn\nimport torch.optim as optim\n\nfrom torchvision import transforms\nfrom torchvision.models.resnet import BasicBlock\n\n# Класс для работы с датасетом изображений\nclass ImageDataset(Dataset):\n    \"\"\"\n    Dataset для загрузки изображений и (опционально) меток классов.\n    \n    Аргументы:\n        image_dir (str): Путь к директории с изображениями (JPG).\n        label_file (str, optional): CSV-файл с метками. Должен содержать столбцы 'Id' и 'Category'.\n        transform (callable, optional): Преобразования, применяемые к изображениям.\n    \"\"\"\n    def __init__(self, image_dir, label_file=None, transform=None):\n        self.image_dir = image_dir\n        self.transform = transform\n\n        # Загрузка меток, если указаны\n        if label_file is not None:\n            self.label_file = pd.read_csv(label_file)\n            # Словарь соответствия: имя файла → категория\n            self.labels = {\n                row['Id']: row['Category'] \n                for _, row in self.label_file.iterrows()\n            }\n            self.has_labels = True\n        else:\n            self.labels = None\n            self.has_labels = False\n\n        # Список файлов изображений (только .jpg, отсортирован по имени)\n        self.image_files = sorted([\n            f for f in os.listdir(image_dir) \n            if f.endswith('.jpg')\n        ])\n\n    def __len__(self):\n        return len(self.image_files)\n\n    def __getitem__(self, idx):\n        # Загружаем изображение\n        image_path = os.path.join(self.image_dir, self.image_files[idx])\n        image = Image.open(image_path).convert(\"RGB\")\n\n        # Применяем трансформации, если заданы\n        if self.transform:\n            image = self.transform(image)\n\n        # Возвращаем (изображение, метка) или только изображение\n        if self.has_labels:\n            label = self.labels[self.image_files[idx]]\n            return image, label\n        else:\n            return image\n\n# Аугментации и нормализация для обучающей выборки\ntrain_transform = transforms.Compose([\n    transforms.Resize((40, 40)),                      # Изменение размера изображения\n    transforms.RandomHorizontalFlip(p=0.5),           # Случайное отражение по горизонтали\n    transforms.RandomRotation(degrees=15),            # Случайный поворот на ±15°\n    transforms.ToTensor(),                            # Преобразование в тензор\n    transforms.Normalize(                             # Нормализация по каналам (ImageNet-совместимая)\n        mean=[0.485, 0.456, 0.406], \n        std=[0.229, 0.224, 0.225]\n    )\n])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T18:23:34.486826Z","iopub.execute_input":"2025-01-23T18:23:34.487140Z","iopub.status.idle":"2025-01-23T18:23:34.496714Z","shell.execute_reply.started":"2025-01-23T18:23:34.487116Z","shell.execute_reply":"2025-01-23T18:23:34.495666Z"}},"outputs":[],"execution_count":42},{"cell_type":"code","source":"# Создание обучающего датасета и DataLoader'а\ntrain_dataset = ImageDataset(\n    image_dir='/kaggle/input/bhw-1-dl-2024-2025/bhw1/trainval',\n    label_file='/kaggle/input/bhw-1-dl-2024-2025/bhw1/labels.csv',\n    transform=train_transform\n)\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n\n# Кастомная реализация ResNet-34 (на основе BasicBlock)\nclass CustomResNet34(nn.Module):\n    def __init__(self, num_classes):\n        super(CustomResNet34, self).__init__()\n        self.inplanes = 64\n\n        # Начальный сверточный блок\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU(inplace=True)\n\n        # Четыре последовательных residual-слоя\n        self.layer1 = self._make_layer(BasicBlock, 64, 3)\n        self.layer2 = self._make_layer(BasicBlock, 128, 4, stride=2)\n        self.layer3 = self._make_layer(BasicBlock, 256, 6, stride=2)\n        self.layer4 = self._make_layer(BasicBlock, 512, 3, stride=2)\n\n        # Усреднение по пространственным координатам и классификатор\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n        self.fc = nn.Linear(512, num_classes)\n\n    def _make_layer(self, block, planes, blocks, stride=1):\n        \"\"\"\n        Создание одного residual-слоя из нескольких блоков.\n        \"\"\"\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            # Понижение размерности (если нужно)\n            downsample = nn.Sequential(\n                nn.Conv2d(self.inplanes, planes * block.expansion,\n                          kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(planes * block.expansion),\n            )\n\n        layers = []\n        # Первый блок может изменять размерность\n        layers.append(block(self.inplanes, planes, stride, downsample))\n        self.inplanes = planes * block.expansion\n\n        # Остальные блоки — обычные\n        for _ in range(1, blocks):\n            layers.append(block(self.inplanes, planes))\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        \"\"\"\n        Прямой проход (forward) через всю сеть.\n        \"\"\"\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.fc(x)\n        return x\n\n# Определяем количество классов по CSV-файлу\nnum_classes = train_dataset.label_file['Category'].nunique()\n\n# Инициализация модели, функции потерь и оптимизатора\nmodel = CustomResNet34(num_classes=num_classes)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(\n    model.parameters(),\n    lr=0.01,\n    momentum=0.9,\n    weight_decay=1e-4\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T18:23:34.497936Z","iopub.execute_input":"2025-01-23T18:23:34.498200Z","iopub.status.idle":"2025-01-23T18:23:39.757961Z","shell.execute_reply.started":"2025-01-23T18:23:34.498177Z","shell.execute_reply":"2025-01-23T18:23:39.756992Z"}},"outputs":[],"execution_count":43},{"cell_type":"code","source":"from tqdm import tqdm\n\n# Параметры обучения\nnum_epochs = 11\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Перенос модели на GPU (если доступен)\nmodel = model.to(device)\n\n# Цикл обучения\nfor epoch in range(num_epochs):\n    model.train()  # Переводим модель в режим обучения\n\n    running_loss = 0.0\n    correct = 0\n    total = 0\n\n    # Итерация по обучающему даталоадеру\n    for inputs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n        inputs, labels = inputs.to(device), labels.to(device)\n\n        optimizer.zero_grad()        # Обнуляем градиенты\n        outputs = model(inputs)      # Прямой проход\n        loss = criterion(outputs, labels)  # Вычисляем loss\n        loss.backward()              # Обратное распространение ошибки\n        optimizer.step()             # Обновление весов\n\n        running_loss += loss.item()\n\n        # Вычисление точности\n        _, predicted = torch.max(outputs, dim=1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\n    # Метрики за эпоху\n    epoch_loss = running_loss / len(train_loader)\n    epoch_accuracy = 100 * correct / total\n\n    print(f\"Epoch [{epoch+1}/{num_epochs}] | \"\n          f\"Loss: {epoch_loss:.4f} | \"\n          f\"Accuracy: {epoch_accuracy:.2f}%\")\n\n# Сохраняем веса модели после завершения обучения\ntorch.save(model.state_dict(), 'model.pth')\nprint(\"✅ Модель сохранена в 'model.pth'\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T18:23:39.759479Z","iopub.execute_input":"2025-01-23T18:23:39.759782Z","iopub.status.idle":"2025-01-23T20:09:43.618569Z","shell.execute_reply.started":"2025-01-23T18:23:39.759749Z","shell.execute_reply":"2025-01-23T20:09:43.617350Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 3125/3125 [09:38<00:00,  5.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [1/11], Loss: 4.7466, Accuracy: 4.88%\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 3125/3125 [09:34<00:00,  5.44it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [2/11], Loss: 4.0685, Accuracy: 12.73%\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 3125/3125 [09:36<00:00,  5.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [3/11], Loss: 3.5918, Accuracy: 19.81%\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 3125/3125 [09:46<00:00,  5.33it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [4/11], Loss: 3.2763, Accuracy: 25.12%\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 3125/3125 [09:36<00:00,  5.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [5/11], Loss: 3.0524, Accuracy: 29.13%\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 3125/3125 [09:31<00:00,  5.47it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [6/11], Loss: 2.8555, Accuracy: 32.83%\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 3125/3125 [10:03<00:00,  5.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [7/11], Loss: 2.6956, Accuracy: 35.90%\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 3125/3125 [09:45<00:00,  5.33it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [8/11], Loss: 2.5488, Accuracy: 38.88%\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 3125/3125 [09:31<00:00,  5.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [9/11], Loss: 2.4312, Accuracy: 41.06%\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 3125/3125 [09:23<00:00,  5.55it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [10/11], Loss: 2.3058, Accuracy: 43.58%\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 3125/3125 [09:35<00:00,  5.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [11/11], Loss: 2.2000, Accuracy: 45.80%\n","output_type":"stream"}],"execution_count":44},{"cell_type":"code","source":"from torchvision import transforms\n\n# Трансформации для тестовых изображений (без аугментаций)\ntest_transform = transforms.Compose([\n    transforms.Resize((40, 40)),  # Приведение к нужному размеру\n    transforms.ToTensor(),        # Перевод в тензор\n    transforms.Normalize(         # Нормализация как в обучении\n        mean=[0.485, 0.456, 0.406],\n        std=[0.229, 0.224, 0.225]\n    )\n])\n\n# Загрузка тестового датасета (без меток)\ntest_dir = '/kaggle/input/bhw-1-dl-2024-2025/bhw1/test'\ntest_dataset = ImageDataset(image_dir=test_dir, label_file=None, transform=test_transform)\n\n# Перевод модели в режим инференса\nmodel.eval()\n\n# Списки для хранения предсказаний и имён файлов\npredictions = []\nimage_ids = []\n\n# Инференс без вычисления градиентов\nwith torch.no_grad():\n    for idx in tqdm(range(len(test_dataset)), desc=\"Predicting\"):\n        image = test_dataset[idx]               # Получаем изображение\n        image = image.unsqueeze(0).to(device)   # Добавляем батч-измерение и на GPU\n\n        outputs = model(image)                  # Предсказание\n        _, predicted = torch.max(outputs, 1)    # Выбор класса с наибольшей вероятностью\n\n        predictions.append(predicted.item())\n        image_ids.append(test_dataset.image_files[idx])\n\n# Сохраняем результат в CSV-файл в формате Kaggle-сабмита\nsubmission = pd.DataFrame({\n    'Id': image_ids,\n    'Category': predictions\n})\nsubmission.to_csv('labels_test.csv', index=False)\nprint(\"✅ Файл labels_test.csv успешно сохранён!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T20:23:35.498507Z","iopub.execute_input":"2025-01-23T20:23:35.498841Z","iopub.status.idle":"2025-01-23T20:24:56.617419Z","shell.execute_reply.started":"2025-01-23T20:23:35.498814Z","shell.execute_reply":"2025-01-23T20:24:56.616664Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 10000/10000 [01:21<00:00, 123.32it/s]\n","output_type":"stream"}],"execution_count":48},{"cell_type":"code","source":"# Переводим модель в режим обучения\nmodel.train()\n\n# Инициализация счетчиков\nrunning_loss = 0.0\ncorrect = 0\ntotal = 0\n\n# Обход всего обучающего набора\nfor inputs, labels in tqdm(train_loader, desc=\"Training\"):\n    inputs, labels = inputs.to(device), labels.to(device)\n\n    # Обнуляем градиенты перед шагом оптимизации\n    optimizer.zero_grad()\n\n    # Прямой проход\n    outputs = model(inputs)\n\n    # Вычисляем loss\n    loss = criterion(outputs, labels)\n\n    # Обратный проход\n    loss.backward()\n\n    # Обновление параметров модели\n    optimizer.step()\n\n    # Суммируем loss\n    running_loss += loss.item()\n\n    # Предсказания: класс с максимальной вероятностью\n    _, predicted = torch.max(outputs, 1)\n\n    # Обновляем счётчики для точности\n    total += labels.size(0)\n    correct += (predicted == labels).sum().item()\n\n# Вычисляем точность за эпоху\naccuracy = 100 * correct / total\nprint(f\"Train Loss: {running_loss / len(train_loader):.4f} | Train Accuracy: {accuracy:.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T20:12:31.675706Z","iopub.execute_input":"2025-01-23T20:12:31.676020Z","iopub.status.idle":"2025-01-23T20:22:05.998149Z","shell.execute_reply.started":"2025-01-23T20:12:31.675988Z","shell.execute_reply":"2025-01-23T20:22:05.997303Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 3125/3125 [09:34<00:00,  5.44it/s]\n","output_type":"stream"}],"execution_count":47},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}